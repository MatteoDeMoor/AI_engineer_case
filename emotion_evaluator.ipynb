{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "929b3c1a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12528f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hogent\\Visual Studio Code\\Projecten\\Sopra_Steria\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Matteo\\AppData\\Local\\Temp\\ipykernel_17468\\3706544885.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from fastapi import FastAPI\n",
    "from threading import Thread\n",
    "from pydantic import BaseModel\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba9d2e",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97cfa84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(Path('data') / 'IMDB-movie-reviews.csv', sep=';', encoding='ISO-8859-1')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e23c76",
   "metadata": {},
   "source": [
    "# Use pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hogent\\Visual Studio Code\\Projecten\\Sopra_Steria\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.34it/s]\n",
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:46<00:00,  6.69s/it]\n",
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:09<00:00,  1.39s/it]\n",
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:09<00:00,  1.33s/it]\n",
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:09<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create the sentiment analysis pipelines\n",
    "distilbert_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    # https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "    device=-1\n",
    ")\n",
    "roberta_large_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"siebert/sentiment-roberta-large-english\",\n",
    "    # https://huggingface.co/siebert/sentiment-roberta-large-english\n",
    "    device=-1\n",
    ")\n",
    "multilingual_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    # https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
    "    device=-1\n",
    ")\n",
    "textattack_bert_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"textattack/bert-base-uncased-SST-2\",\n",
    "    # https://huggingface.co/textattack/bert-base-uncased-SST-2\n",
    "    device=-1\n",
    ")\n",
    "textattack_roberta_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"textattack/roberta-base-SST-2\",\n",
    "    # https://huggingface.co/textattack/roberta-base-SST-2\n",
    "    device=-1\n",
    ")\n",
    "twitter_roberta_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    # https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# Function to predict in batches\n",
    "def batch_predict(pipe, texts, batch_size=16, max_length=512):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
    "        batch = [t[:max_length] for t in texts[i : i + batch_size]]\n",
    "        preds = pipe(batch)\n",
    "        results.extend(preds)\n",
    "    return results\n",
    "\n",
    "# Make predictions\n",
    "texts = df['review'].tolist()\n",
    "preds_distilbert = batch_predict(distilbert_pipeline, texts)\n",
    "preds_roberta_large = batch_predict(roberta_large_pipeline, texts)\n",
    "preds_multilingual = batch_predict(multilingual_pipeline, texts)\n",
    "preds_textattack_bert = batch_predict(textattack_bert_pipeline, texts)\n",
    "preds_textattack_roberta = batch_predict(textattack_roberta_pipeline, texts)\n",
    "preds_twitter_roberta = batch_predict(twitter_roberta_pipeline, texts)\n",
    "\n",
    "# Unpack to labels and scores\n",
    "df['label_distilbert']       = [p['label'] for p in preds_distilbert]\n",
    "df['score_distilbert']       = [p['score'] for p in preds_distilbert]\n",
    "\n",
    "df['label_roberta_large']    = [p['label'] for p in preds_roberta_large]\n",
    "df['score_roberta_large']    = [p['score'] for p in preds_roberta_large]\n",
    "\n",
    "df['label_multilingual']     = [p['label'] for p in preds_multilingual]\n",
    "df['score_multilingual']     = [p['score'] for p in preds_multilingual]\n",
    "\n",
    "df['label_textattack_bert']  = [p['label'] for p in preds_textattack_bert]\n",
    "df['score_textattack_bert']  = [p['score'] for p in preds_textattack_bert]\n",
    "\n",
    "df['label_textattack_roberta']= [p['label'] for p in preds_textattack_roberta]\n",
    "df['score_textattack_roberta']= [p['score'] for p in preds_textattack_roberta]\n",
    "\n",
    "df['label_twitter_roberta']  = [p['label'] for p in preds_twitter_roberta]\n",
    "df['score_twitter_roberta']  = [p['score'] for p in preds_twitter_roberta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c9e31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_distilbert</th>\n",
       "      <th>score_distilbert</th>\n",
       "      <th>label_roberta_large</th>\n",
       "      <th>score_roberta_large</th>\n",
       "      <th>label_multilingual</th>\n",
       "      <th>score_multilingual</th>\n",
       "      <th>label_textattack_bert</th>\n",
       "      <th>score_textattack_bert</th>\n",
       "      <th>label_textattack_roberta</th>\n",
       "      <th>score_textattack_roberta</th>\n",
       "      <th>label_twitter_roberta</th>\n",
       "      <th>score_twitter_roberta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.601758</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>0.266522</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.989746</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.946431</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.470995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.506213</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.973879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998933</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>0.421487</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.997534</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.821539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>0.426351</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.984107</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.596891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999811</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>0.532169</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.994273</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.870845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998879</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.527373</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.999295</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.997080</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.965920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.973266</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998406</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>0.305226</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.990563</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.795830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>1 star</td>\n",
       "      <td>0.527377</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.991240</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.887934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>1 star</td>\n",
       "      <td>0.780873</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.998682</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.995693</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.941357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.736615</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.978246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "5  Probably my all-time favorite movie, a story o...  positive   \n",
       "6  I sure would like to see a resurrection of a u...  positive   \n",
       "7  This show was an amazing, fresh & innovative i...  negative   \n",
       "8  Encouraged by the positive comments about this...  negative   \n",
       "9  If you like original gut wrenching laughter yo...  positive   \n",
       "\n",
       "  label_distilbert  score_distilbert label_roberta_large  score_roberta_large  \\\n",
       "0         NEGATIVE          0.601758            POSITIVE             0.998774   \n",
       "1         POSITIVE          0.999700            POSITIVE             0.998925   \n",
       "2         POSITIVE          0.999031            POSITIVE             0.998933   \n",
       "3         NEGATIVE          0.999282            NEGATIVE             0.999474   \n",
       "4         POSITIVE          0.999811            POSITIVE             0.998887   \n",
       "5         POSITIVE          0.999543            POSITIVE             0.998879   \n",
       "6         POSITIVE          0.973266            POSITIVE             0.998406   \n",
       "7         NEGATIVE          0.999639            NEGATIVE             0.999511   \n",
       "8         NEGATIVE          0.999747            NEGATIVE             0.999517   \n",
       "9         POSITIVE          0.999701            POSITIVE             0.998900   \n",
       "\n",
       "  label_multilingual  score_multilingual label_textattack_bert  \\\n",
       "0            2 stars            0.266522               LABEL_1   \n",
       "1            5 stars            0.506213               LABEL_1   \n",
       "2            4 stars            0.421487               LABEL_1   \n",
       "3            3 stars            0.426351               LABEL_0   \n",
       "4            4 stars            0.532169               LABEL_1   \n",
       "5            5 stars            0.527373               LABEL_1   \n",
       "6            3 stars            0.305226               LABEL_1   \n",
       "7             1 star            0.527377               LABEL_0   \n",
       "8             1 star            0.780873               LABEL_0   \n",
       "9            5 stars            0.736615               LABEL_1   \n",
       "\n",
       "   score_textattack_bert label_textattack_roberta  score_textattack_roberta  \\\n",
       "0               0.989746                  LABEL_1                  0.946431   \n",
       "1               0.999622                  LABEL_1                  0.999189   \n",
       "2               0.999445                  LABEL_1                  0.997534   \n",
       "3               0.983810                  LABEL_0                  0.984107   \n",
       "4               0.999538                  LABEL_1                  0.994273   \n",
       "5               0.999295                  LABEL_1                  0.997080   \n",
       "6               0.997984                  LABEL_1                  0.990563   \n",
       "7               0.998305                  LABEL_0                  0.991240   \n",
       "8               0.998682                  LABEL_0                  0.995693   \n",
       "9               0.999583                  LABEL_1                  0.998446   \n",
       "\n",
       "  label_twitter_roberta  score_twitter_roberta  \n",
       "0               LABEL_1               0.470995  \n",
       "1               LABEL_2               0.973879  \n",
       "2               LABEL_2               0.821539  \n",
       "3               LABEL_0               0.596891  \n",
       "4               LABEL_2               0.870845  \n",
       "5               LABEL_2               0.965920  \n",
       "6               LABEL_2               0.795830  \n",
       "7               LABEL_0               0.887934  \n",
       "8               LABEL_0               0.941357  \n",
       "9               LABEL_2               0.978246  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d0eae",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result/sentiment_benchmarks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e70732",
   "metadata": {},
   "source": [
    "# Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b03134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distilbert ===\n",
      "Accuracy: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88        58\n",
      "    positive       0.85      0.81      0.83        42\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.86      0.85      0.86       100\n",
      "weighted avg       0.86      0.86      0.86       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52  6]\n",
      " [ 8 34]]\n",
      "\n",
      "=== Roberta Large ===\n",
      "Accuracy: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.94        58\n",
      "    positive       0.89      0.95      0.92        42\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53  5]\n",
      " [ 2 40]]\n",
      "\n",
      "=== Multilingual ===\n",
      "Accuracy: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.74      0.82        58\n",
      "    positive       0.72      0.90      0.80        42\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.82      0.82      0.81       100\n",
      "weighted avg       0.83      0.81      0.81       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[43 15]\n",
      " [ 4 38]]\n",
      "\n",
      "=== Textattack Bert ===\n",
      "Accuracy: 0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89        58\n",
      "    positive       0.85      0.83      0.84        42\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.87      0.86      0.87       100\n",
      "weighted avg       0.87      0.87      0.87       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52  6]\n",
      " [ 7 35]]\n",
      "\n",
      "=== Textattack Roberta ===\n",
      "Accuracy: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        58\n",
      "    positive       0.92      0.79      0.85        42\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.89      0.87      0.87       100\n",
      "weighted avg       0.88      0.88      0.88       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[55  3]\n",
      " [ 9 33]]\n",
      "\n",
      "=== Twitter Roberta ===\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.86        58\n",
      "    positive       0.88      0.69      0.77        42\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.84      0.81      0.82       100\n",
      "weighted avg       0.84      0.83      0.83       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54  4]\n",
      " [13 29]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mapping helpers\n",
    "def star2bin(label):\n",
    "    stars = int(label.split()[0])\n",
    "    return 'negative' if stars <= 2 else 'positive'\n",
    "\n",
    "def ta_label2bin(label):\n",
    "    return 'positive' if label == 'LABEL_1' else 'negative'\n",
    "\n",
    "def tw_roberta3bin(label):\n",
    "    return 'positive' if label == 'LABEL_2' or label.lower() == 'positive' else 'negative'\n",
    "\n",
    "# Create binary predictions matching your renamed columns\n",
    "df['pred_distilbert']        = df['label_distilbert'].str.lower()\n",
    "df['pred_roberta_large']     = df['label_roberta_large'].str.lower()\n",
    "df['pred_multilingual']      = df['label_multilingual'].apply(star2bin)\n",
    "df['pred_textattack_bert']   = df['label_textattack_bert'].apply(ta_label2bin)\n",
    "df['pred_textattack_roberta']= df['label_textattack_roberta'].apply(ta_label2bin)\n",
    "df['pred_twitter_roberta']   = df['label_twitter_roberta'].apply(tw_roberta3bin)\n",
    "\n",
    "# True labels\n",
    "y_true = df['sentiment']\n",
    "\n",
    "# Iterate over each model and print metrics\n",
    "model_keys = [\n",
    "    'distilbert',\n",
    "    'roberta_large',\n",
    "    'multilingual',\n",
    "    'textattack_bert',\n",
    "    'textattack_roberta',\n",
    "    'twitter_roberta'\n",
    "]\n",
    "\n",
    "for key in model_keys:\n",
    "    y_pred = df[f'pred_{key}']\n",
    "    print(f\"=== {key.replace('_', ' ').title()} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e1d0bb",
   "metadata": {},
   "source": [
    "# Save benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92dbc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from model key to human-readable name\n",
    "model_names = {\n",
    "    'distilbert': \"DistilBERT-SST2\",\n",
    "    'roberta_large': \"Siebert RoBERTa-large\",\n",
    "    'multilingual': \"nlptown 1-5 stars\",\n",
    "    'textattack_bert': \"TextAttack BERT-SST2\",\n",
    "    'textattack_roberta': \"TextAttack RoBERTa-SST2\",\n",
    "    'twitter_roberta': \"CardiffNLP Twitter RoBERTa\",\n",
    "}\n",
    "\n",
    "# Write consolidated benchmark report\n",
    "with open(\"result/benchmark_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for key, name in model_names.items():\n",
    "        y_pred = df[f\"pred_{key}\"]\n",
    "        f.write(f\"{name}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\\n\\n\")\n",
    "        f.write(classification_report(y_true, y_pred, zero_division=0))\n",
    "        f.write(\"\\n\" + \"-\" * 50 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d983d",
   "metadata": {},
   "source": [
    "# Interactive demo with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d134bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38034 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:38034 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Mapping human-readable names to your pipelines\n",
    "pipeline_map = {\n",
    "    \"DistilBERT-SST2\": distilbert_pipeline,\n",
    "    \"RoBERTa-large SST2\": roberta_large_pipeline,\n",
    "    \"nlptown Multilingual\": multilingual_pipeline,\n",
    "    \"TextAttack BERT-SST2\": textattack_bert_pipeline,\n",
    "    \"TextAttack RoBERTa-SST2\": textattack_roberta_pipeline,\n",
    "    \"Twitter RoBERTa\": twitter_roberta_pipeline,\n",
    "}\n",
    "\n",
    "# Unified label mappers for each model\n",
    "label_mappers = {\n",
    "    \"DistilBERT-SST2\":        lambda raw: raw.capitalize(),\n",
    "    \"RoBERTa-large SST2\":     lambda raw: raw.capitalize(),\n",
    "    \"nlptown Multilingual\":   lambda raw: \"Positive\" if int(raw.split()[0]) >= 3 else \"Negative\",\n",
    "    \"TextAttack BERT-SST2\":   lambda raw: \"Positive\" if raw == \"LABEL_1\" else \"Negative\",\n",
    "    \"TextAttack RoBERTa-SST2\":lambda raw: \"Positive\" if raw == \"LABEL_1\" else \"Negative\",\n",
    "    \"Twitter RoBERTa\":        lambda raw: \"Positive\" if raw == \"LABEL_2\" else \"Negative\",\n",
    "}\n",
    "\n",
    "def classify(text: str, model_name: str):\n",
    "    pipe   = pipeline_map[model_name]\n",
    "    raw    = pipe(text[:512])[0][\"label\"]\n",
    "    score  = float(pipe(text[:512])[0][\"score\"])\n",
    "    label  = label_mappers[model_name](raw)\n",
    "    return label, score\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=classify,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=5, placeholder=\"Type a movie reviewâ€¦\", label=\"Review\"),\n",
    "        gr.Radio(choices=list(pipeline_map.keys()), label=\"Model\",\n",
    "                 value=\"DistilBERT-SST2\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=1, label=\"Predicted Sentiment\"),\n",
    "        gr.Number(label=\"Confidence\"),\n",
    "    ],\n",
    "    title=\"IMDB Review Sentiment Demo\",\n",
    "    description=\"Pick a model and see Positive vs. Negative\",\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31510aa1",
   "metadata": {},
   "source": [
    "# Predict API with FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de758ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ API running at http://127.0.0.1:8000/docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [17468]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "# Reuse your pipeline_map and label_mappers from above\n",
    "app = FastAPI(title=\"IMDB Sentiment API\")\n",
    "\n",
    "class ReviewRequest(BaseModel):\n",
    "    text: str\n",
    "    model: str  = \"DistilBERT-SST2\"\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(req: ReviewRequest):\n",
    "    if req.model not in pipeline_map:\n",
    "        return {\n",
    "            \"error\": f\"Unknown model '{req.model}'. \"\n",
    "                     f\"Choose from: {list(pipeline_map.keys())}\"\n",
    "        }\n",
    "    pipe  = pipeline_map[req.model]\n",
    "    raw   = pipe(req.text[:512])[0]\n",
    "    label = label_mappers[req.model](raw[\"label\"])\n",
    "    score = float(raw[\"score\"])\n",
    "    return {\n",
    "        \"model\": req.model,\n",
    "        \"label\": label,\n",
    "        \"score\": round(score, 4)\n",
    "    }\n",
    "\n",
    "# Launch FastAPI in a background thread\n",
    "def _run_api():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"info\")\n",
    "\n",
    "thread = Thread(target=_run_api, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "print(\"ðŸš€ API running at http://127.0.0.1:8000/docs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
