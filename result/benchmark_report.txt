Model 1 (DistilBERT-SST2)
Accuracy: 0.8600

              precision    recall  f1-score   support

    negative       0.87      0.90      0.88        58
    positive       0.85      0.81      0.83        42

    accuracy                           0.86       100
   macro avg       0.86      0.85      0.86       100
weighted avg       0.86      0.86      0.86       100

----------------------------------------

Model 2 (nlptown Multilingual)
Accuracy: 0.8100

              precision    recall  f1-score   support

    negative       0.91      0.74      0.82        58
    positive       0.72      0.90      0.80        42

    accuracy                           0.81       100
   macro avg       0.82      0.82      0.81       100
weighted avg       0.83      0.81      0.81       100

----------------------------------------

Model 3 (Twitter-RoBERTa)
Accuracy: 0.5800

              precision    recall  f1-score   support

    negative       0.58      1.00      0.73        58
    positive       0.00      0.00      0.00        42

    accuracy                           0.58       100
   macro avg       0.29      0.50      0.37       100
weighted avg       0.34      0.58      0.43       100

----------------------------------------

Model 4 (RoBERTa-large SST2)
Accuracy: 0.9300

              precision    recall  f1-score   support

    negative       0.96      0.91      0.94        58
    positive       0.89      0.95      0.92        42

    accuracy                           0.93       100
   macro avg       0.93      0.93      0.93       100
weighted avg       0.93      0.93      0.93       100

----------------------------------------

